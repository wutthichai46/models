releases:
  versioned:
    tag_specs:
    - '{spr-3d-unet-mlperf-inference}'
slice_sets:
  spr-3d-unet-mlperf-inference:
    - add_to_name: tf-spr-3d-unet-mlperf-inference
      dockerfile_subdirectory: tensorflow-spr
      args:
        - PACKAGE_NAME=tf-spr-3d-unet-mlperf-inference
        - TENSORFLOW_IMAGE=model-zoo
        - TENSORFLOW_TAG=tensorflow-spr
      partials:
        - tensorflow/tensorflow-base
        - model_package
        - numactl
        - image_segmentation/3d_unet_mlperf_pip_installs
        - entrypoint
      files:
        - destination: benchmarks/common
          source: benchmarks/common
        - destination: benchmarks/image_segmentation/__init__.py
          source: benchmarks/image_segmentation/__init__.py
        - destination: benchmarks/image_segmentation/tensorflow/3d_unet_mlperf/inference
          source: benchmarks/image_segmentation/tensorflow/3d_unet_mlperf/inference
        - destination: benchmarks/launch_benchmark.py
          source: benchmarks/launch_benchmark.py
        - source: quickstart/image_segmentation/tensorflow/3d_unet_mlperf/inference/cpu/inference_realtime_multi_instance.sh
          destination: quickstart/inference_realtime.sh
        - source: quickstart/image_segmentation/tensorflow/3d_unet_mlperf/inference/cpu/inference_throughput_multi_instance.sh
          destination: quickstart/inference_throughput.sh
        - source: quickstart/image_segmentation/tensorflow/3d_unet_mlperf/inference/cpu/accuracy.sh
          destination: quickstart/accuracy.sh
        - destination: models/common
          source: models/common
        - destination: models/image_segmentation/tensorflow/3d_unet_mlperf/inference
          source: models/image_segmentation/tensorflow/3d_unet_mlperf/inference
        - destination: quickstart/common
          source: quickstart/common
      downloads:
      - source: https://storage.googleapis.com/intel-optimized-tensorflow/models/2_10_0/3dunet_dynamic_ndhwc.pb
        destination: pretrained_model/3dunet_dynamic_ndhwc.pb
      - source: https://storage.googleapis.com/intel-optimized-tensorflow/models/2_10_0/3dunet_new_int8_bf16.pb
        destination: pretrained_model/3dunet_new_int8_bf16.pb
      wrapper_package_files:
        - source: output/tf-spr-3d-unet-mlperf-inference.tar.gz
          destination: model_packages/tf-spr-3d-unet-mlperf-inference.tar.gz
        - source: quickstart/image_segmentation/tensorflow/3d_unet_mlperf/inference/cpu/build.sh
          destination: build.sh
        - source: quickstart/image_segmentation/tensorflow/3d_unet_mlperf/inference/cpu/run.sh
          destination: run.sh
        - source: dockerfiles/tensorflow-spr/tf-spr-3d-unet-mlperf-inference.Dockerfile
          destination: tf-spr-3d-unet-mlperf-inference.Dockerfile
        - source: LICENSE
          destination: licenses/LICENSE
        - source: third_party
          destination: licenses/third_party
      documentation:
        - docs:
          - name: Title
            uri: models/quickstart/image_segmentation/tensorflow/3d_unet_mlperf/inference/cpu/.docs/title.md
          - name: Description
            uri: models/quickstart/image_segmentation/tensorflow/3d_unet_mlperf/inference/cpu/.docs/description.md
          - name: Datasets
            uri: models/quickstart/image_segmentation/tensorflow/3d_unet_mlperf/inference/cpu/.docs/datasets.md
          - name: Quick Start Scripts
            uri: models/quickstart/image_segmentation/tensorflow/3d_unet_mlperf/inference/cpu/.docs/quickstart.md
          - name: Bare Metal
            uri: models/quickstart/image_segmentation/tensorflow/3d_unet_mlperf/inference/cpu/.docs/baremetal.md
          - name: License
            uri: models/quickstart/image_segmentation/tensorflow/3d_unet_mlperf/inference/cpu/.docs/license.md
          name: README.md
          text_replace:
            <mode>: inference
            <model name>: MLPerf 3D U-Net
            <use case>: image_segmentation
            <workload container url>: ""
          uri: models/benchmarks/image_segmentation/tensorflow/3d_unet_mlperf/inference
