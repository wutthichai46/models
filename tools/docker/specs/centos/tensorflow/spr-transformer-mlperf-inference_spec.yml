releases:
  versioned:
    tag_specs:
    - '{spr-transformer-mlperf-inference}'
slice_sets:
  spr-transformer-mlperf-inference:
    - add_to_name: tf-spr-transformer-mlperf-inference
      dockerfile_subdirectory: tensorflow-spr
      args:
        - PACKAGE_NAME=tf-spr-transformer-mlperf-inference
        - TENSORFLOW_IMAGE=model-zoo
        - TENSORFLOW_TAG=tensorflow-spr
      partials:
        - tensorflow/tensorflow-base
        - common
        - model_package
        - entrypoint
      files:
        - destination: benchmarks/common
          source: benchmarks/common
        - destination: benchmarks/object_detection/__init__.py
          source: benchmarks/object_detection/__init__.py
        - destination: benchmarks/language_translation/tensorflow/__init__.py
          source: benchmarks/language_translation/tensorflow/__init__.py
        - destination: benchmarks/language_translation/tensorflow/transformer_mlperf/README.md
          source: benchmarks/language_translation/tensorflow/transformer_mlperf/README.md
        - destination: benchmarks/language_translation/tensorflow/transformer_mlperf/inference
          source: benchmarks/language_translation/tensorflow/transformer_mlperf/inference
        - destination: benchmarks/launch_benchmark.py
          source: benchmarks/launch_benchmark.py
        - source: quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/inference_realtime.sh
          destination: quickstart/inference_realtime.sh
        - source: quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/inference_throughput.sh
          destination: quickstart/inference_throughput.sh
        - source: quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/accuracy.sh
          destination: quickstart/accuracy.sh
        - destination: models/common
          source: models/common
        - destination: models/language_translation/tensorflow/transformer_mlperf/inference
          source: models/language_translation/tensorflow/transformer_mlperf/inference
        - destination: quickstart/common
          source: quickstart/common
      downloads:
        - source: https://storage.googleapis.com/intel-optimized-tensorflow/models/2_10_0/transformer_mlperf_bf16.pb
          destination: pretrained_model/transformer_mlperf_bf16.pb
        - source: https://storage.googleapis.com/intel-optimized-tensorflow/models/2_10_0/transformer_mlperf_fp32.pb
          destination: pretrained_model/transformer_mlperf_fp32.pb
        - source: https://storage.googleapis.com/intel-optimized-tensorflow/models/2_10_0/transformer_mlperf_int8.pb
          destination: pretrained_model/transformer_mlperf_int8.pb
      wrapper_package_files:
        - source: output/tf-spr-transformer-mlperf-inference.tar.gz
          destination: model_packages/tf-spr-transformer-mlperf-inference.tar.gz
        - source: quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/build.sh
          destination: build.sh
        - source: quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/run.sh
          destination: run.sh
        - source: dockerfiles/tensorflow-spr/tf-spr-transformer-mlperf-inference.Dockerfile
          destination: tf-spr-transformer-mlperf-inference.Dockerfile
        - source: LICENSE
          destination: licenses/LICENSE
        - source: third_party
          destination: licenses/third_party
