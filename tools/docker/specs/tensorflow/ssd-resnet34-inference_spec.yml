releases:
  versioned:
    tag_specs:
    - '{_TAG_PREFIX}{intel-tf}{object-detection}{ssd-resnet34-inference}'
slice_sets:
  ssd-resnet34-inference:
  - add_to_name: -ssd-resnet34-inference
    args:
    - TENSORFLOW_IMAGE=intel/intel-optimized-tensorflow
    - PACKAGE_NAME=ssd-resnet34-inference
    - CODE_DIR=/workspace/tf_models
    - TF_MODELS_BRANCH=f505cecde2d8ebf6fe15f40fb8bc350b2b1ed5dc
    - TF_BENCHMARKS_DIR=/workspace/ssd-resnet-benchmarks
    - TF_BENCHMARKS_BRANCH=509b9d288937216ca7069f31cfb22aaa7db6a4a7
    dockerfile_subdirectory: model_containers
    documentation:
      - docs:
        - name: Title
          uri: models/quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/.docs/title.md
        - name: Description
          uri: models/quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/.docs/description.md
        - name: Datasets
          uri: models/quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/.docs/datasets.md
        - name: Quick Start Scripts
          uri: models/quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/.docs/quickstart.md
        - name: Docker
          uri: models/quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/.docs/docker_spr.md
        - name: License
          uri: models/quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/.docs/license.md
        name: README.md
        text_replace:
          <docker image>: intel/object-detection:tf-latest-ssd-resnet34-inference
          <mode>: inference
          <model name>: SSD-ResNet34
          <use case>: object_detection
        uri: models/quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu
      - docs:
        - name: Title
          uri: models/quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/.docs/title.md
        - name: Description
          uri: models/quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/.docs/description.md
        - name: Datasets
          uri: models/quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/.docs/datasets.md
        - name: Quick Start Scripts
          uri: models/quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/.docs/quickstart.md
        - name: Bare Metal
          uri: models/quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/.docs/baremetal.md
        - name: Resources
          uri: models/quickstart/common/.docs/resources_with_portal_link.md
        name: README.md
        text_replace:
          <mode>: inference
          <fp32 precision>: FP32
          <fp32 advanced readme link>: fp32/Advanced.md
          <int8 precision>: Int8
          <int8 advanced readme link>: int8/Advanced.md
          <bfloat16 precision>: BFloat16
          <bfloat16 advanced readme link>: bfloat16/Advanced.md
          <model name>: SSD-ResNet34
          <use case>: object_detection
          <workload container url>: https://software.intel.com/content/www/us/en/develop/articles/containers/ssd-resnet34-fp32-inference-tensorflow-container.html
        uri: models/benchmarks/object_detection/tensorflow/ssd-resnet34/inference
      - docs:
        - name: Title
          uri: models/quickstart/common/.docs/advanced/title.md
        - name: Description
          uri: models/quickstart/common/.docs/advanced/description.md
        - name: Setup
          uri: models/quickstart/common/.docs/advanced/setup.md
        - name: Docker arg
          uri: models/quickstart/common/.docs/advanced/docker_arg.md
        - name: Launch benchmark instructions
          uri: models/benchmarks/object_detection/tensorflow/ssd-resnet34/inference/int8/.docs/advanced/launch_benchmark_instructions.md
        name: Advanced.md
        text_replace:
          <mode>: inference
          <model name>: SSD-ResNet34
          <precision>: Int8
          <use case>: object_detection
          <docker image>: 'intel/intel-optimized-tensorflow:latest'
        uri: models/benchmarks/object_detection/tensorflow/ssd-resnet34/inference/int8
      - docs:
        - name: Title
          uri: models/quickstart/common/.docs/advanced/title.md
        - name: Description
          uri: models/quickstart/common/.docs/advanced/description.md
        - name: Setup
          uri: models/quickstart/common/.docs/advanced/setup.md
        - name: Docker arg
          uri: models/quickstart/common/.docs/advanced/docker_arg.md
        - name: Launch benchmark instructions
          uri: models/benchmarks/object_detection/tensorflow/ssd-resnet34/inference/fp32/.docs/advanced/launch_benchmark_instructions.md
        name: Advanced.md
        text_replace:
          <mode>: inference
          <model name>: SSD-ResNet34
          <precision>: FP32
          <use case>: object_detection
          <docker image>: 'intel/intel-optimized-tensorflow:latest'
        uri: models/benchmarks/object_detection/tensorflow/ssd-resnet34/inference/fp32
      - docs:
        - name: Title
          uri: models/quickstart/common/.docs/advanced/title.md
        - name: Description
          uri: models/quickstart/common/.docs/advanced/description.md
        - name: Setup
          uri: models/quickstart/common/.docs/advanced/setup.md
        - name: Docker arg
          uri: models/quickstart/common/.docs/advanced/docker_arg.md
        - name: Launch benchmark instructions
          uri: models/benchmarks/object_detection/tensorflow/ssd-resnet34/inference/bfloat16/.docs/advanced/launch_benchmark_instructions.md
        name: Advanced.md
        text_replace:
          <mode>: inference
          <model name>: SSD-ResNet34
          <precision>: BFloat16
          <use case>: object_detection
          <docker image>: 'intel/intel-optimized-tensorflow:latest'
        uri: models/benchmarks/object_detection/tensorflow/ssd-resnet34/inference/bfloat16
    downloads:
    - source: https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_8/ssd_resnet34_int8_bs1_pretrained_model.pb
      destination: pretrained_models/ssd_resnet34_int8_bs1_pretrained_model.pb
    - source: https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_8/ssd_resnet34_int8_1200x1200_pretrained_model.pb
      destination: pretrained_models/ssd_resnet34_int8_1200x1200_pretrained_model.pb
    - source: https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/ssd_resnet34_fp32_bs1_pretrained_model.pb
      destination: pretrained_model/ssd_resnet34_fp32_bs1_pretrained_model.pb
    - source: https://storage.googleapis.com/intel-optimized-tensorflow/models/ssd_resnet34_fp32_1200x1200_pretrained_model.pb
      destination: pretrained_model/ssd_resnet34_fp32_1200x1200_pretrained_model.pb
    - source: https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_8/ssd_resnet34_fp32_bs1_pretrained_model.pb
      destination: pretrained_models/ssd_resnet34_fp32_bs1_pretrained_model.pb
    - source: https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_8/ssd_resnet34_fp32_1200x1200_pretrained_model.pb
      destination: pretrained_models/ssd_resnet34_fp32_1200x1200_pretrained_model.pb
    files:
    - destination: benchmarks/common
      source: benchmarks/common
    - destination: benchmarks/launch_benchmark.py
      source: benchmarks/launch_benchmark.py
    - destination: benchmarks/object_detection/__init__.py
      source: benchmarks/object_detection/__init__.py
    - destination: benchmarks/object_detection/tensorflow/__init__.py
      source: benchmarks/object_detection/tensorflow/__init__.py
    - destination: benchmarks/object_detection/tensorflow/ssd-resnet34/__init__.py
      source: benchmarks/object_detection/tensorflow/ssd-resnet34/__init__.py
    - destination: benchmarks/object_detection/tensorflow/ssd-resnet34/inference/__init__.py
      source: benchmarks/object_detection/tensorflow/ssd-resnet34/inference/__init__.py
    - destination: benchmarks/object_detection/tensorflow/ssd-resnet34/inference
      source: benchmarks/object_detection/tensorflow/ssd-resnet34/inference
    - destination: models/common
      source: models/common
    - destination: models/object_detection/tensorflow/ssd-resnet34/inference
      source: models/object_detection/tensorflow/ssd-resnet34/inference
    - destination: models/object_detection/tensorflow/ssd-resnet34/inference/tensorflow_benchmarks_tf2.0.patch
      source: models/object_detection/tensorflow/ssd-resnet34/inference/tensorflow_benchmarks_tf2.0.patch
    - destination: models/object_detection/tensorflow/ssd-resnet34/inference/tensorflow_models_tf2.0.patch
      source: models/object_detection/tensorflow/ssd-resnet34/inference/tensorflow_models_tf2.0.patch
    - destination: models/object_detection/tensorflow/ssd-resnet34/inference/tf_benchmarks.patch
      source: models/object_detection/tensorflow/ssd-resnet34/inference/tf_benchmarks.patch
    - destination: quickstart/common
      source: quickstart/common
    - destination: quickstart
      source: quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu
    partials:
    - libgl
    - opencv
    - tensorflow-addons-0.17.1
    - tcmalloc
    - model_package
    - entrypoint
    - tensorflow/benchmarks-source
    - numactl 
